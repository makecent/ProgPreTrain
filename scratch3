/home/louis/miniconda3/envs/open-mmlab/bin/python /home/louis/PycharmProjects/ProgPreTrain/scratch.py
| module                                                           | #parameters or shape   | #flops      |
|:-----------------------------------------------------------------|:-----------------------|:------------|
| model                                                            | 61.005M                | 0.101T      |
|  cls_token                                                       |  (1, 1, 768)           |             |
|  pos_embed                                                       |  (1, 197, 768)         |             |
|  time_embed                                                      |  (1, 8, 768)           |             |
|  patch_embed.projection                                          |  0.591M                |  0.925G     |
|   patch_embed.projection.weight                                  |   (768, 3, 16, 16)     |             |
|   patch_embed.projection.bias                                    |   (768,)               |             |
|  norm                                                            |  1.536K                |  6.025M     |
|   norm.weight                                                    |   (768,)               |             |
|   norm.bias                                                      |   (768,)               |             |
|  transformer_layers.layers                                       |  60.254M               |  0.1T       |
|   transformer_layers.layers.0                                    |   10.042M              |   16.729G   |
|    transformer_layers.layers.0.attentions.0                      |    5.318M              |    9.32G    |
|     transformer_layers.layers.0.attentions.0.norm1               |     1.536K             |     6.774M  |
|      transformer_layers.layers.0.attentions.0.norm1.weight       |      (768,)            |             |
|      transformer_layers.layers.0.attentions.0.norm1.bias         |      (768,)            |             |
|     transformer_layers.layers.0.attentions.0.norm2               |     1.536K             |     6.052M  |
|      transformer_layers.layers.0.attentions.0.norm2.weight       |      (768,)            |             |
|      transformer_layers.layers.0.attentions.0.norm2.bias         |      (768,)            |             |
|     transformer_layers.layers.0.attentions.0.block_in            |     1.772M             |     3.121G  |
|      transformer_layers.layers.0.attentions.0.block_in.weight    |      (2304, 768)       |             |
|      transformer_layers.layers.0.attentions.0.block_in.bias      |      (2304,)           |             |
|     transformer_layers.layers.0.attentions.0.out_proj            |     0.591M             |     1.04G   |
|      transformer_layers.layers.0.attentions.0.out_proj.weight    |      (768, 768)        |             |
|      transformer_layers.layers.0.attentions.0.out_proj.bias      |      (768,)            |             |
|     transformer_layers.layers.0.attentions.0.in_proj             |     1.772M             |     2.789G  |
|      transformer_layers.layers.0.attentions.0.in_proj.weight     |      (2304, 768)       |             |
|      transformer_layers.layers.0.attentions.0.in_proj.bias       |      (2304,)           |             |
|     transformer_layers.layers.0.attentions.0.block_out           |     0.591M             |     0.93G   |
|      transformer_layers.layers.0.attentions.0.block_out.weight   |      (768, 768)        |             |
|      transformer_layers.layers.0.attentions.0.block_out.bias     |      (768,)            |             |
|     transformer_layers.layers.0.attentions.0.temporal_fc         |     0.591M             |     0.925G  |
|      transformer_layers.layers.0.attentions.0.temporal_fc.weight |      (768, 768)        |             |
|      transformer_layers.layers.0.attentions.0.temporal_fc.bias   |      (768,)            |             |
|    transformer_layers.layers.0.ffns.0                            |    4.724M              |    7.409G   |
|     transformer_layers.layers.0.ffns.0.layers                    |     4.722M             |     7.403G  |
|      transformer_layers.layers.0.ffns.0.layers.0.0               |      2.362M            |      3.702G |
|       transformer_layers.layers.0.ffns.0.layers.0.0.weight       |       (3072, 768)      |             |
|       transformer_layers.layers.0.ffns.0.layers.0.0.bias         |       (3072,)          |             |
|      transformer_layers.layers.0.ffns.0.layers.1                 |      2.36M             |      3.702G |
|       transformer_layers.layers.0.ffns.0.layers.1.weight         |       (768, 3072)      |             |
|       transformer_layers.layers.0.ffns.0.layers.1.bias           |       (768,)           |             |
|     transformer_layers.layers.0.ffns.0.norm                      |     1.536K             |     6.025M  |
|      transformer_layers.layers.0.ffns.0.norm.weight              |      (768,)            |             |
|      transformer_layers.layers.0.ffns.0.norm.bias                |      (768,)            |             |
|   transformer_layers.layers.1                                    |   10.042M              |   16.729G   |
|    transformer_layers.layers.1.attentions.0                      |    5.318M              |    9.32G    |
|     transformer_layers.layers.1.attentions.0.norm1               |     1.536K             |     6.774M  |
|      transformer_layers.layers.1.attentions.0.norm1.weight       |      (768,)            |             |
|      transformer_layers.layers.1.attentions.0.norm1.bias         |      (768,)            |             |
|     transformer_layers.layers.1.attentions.0.norm2               |     1.536K             |     6.052M  |
|      transformer_layers.layers.1.attentions.0.norm2.weight       |      (768,)            |             |
|      transformer_layers.layers.1.attentions.0.norm2.bias         |      (768,)            |             |
|     transformer_layers.layers.1.attentions.0.block_in            |     1.772M             |     3.121G  |
|      transformer_layers.layers.1.attentions.0.block_in.weight    |      (2304, 768)       |             |
|      transformer_layers.layers.1.attentions.0.block_in.bias      |      (2304,)           |             |
|     transformer_layers.layers.1.attentions.0.out_proj            |     0.591M             |     1.04G   |
|      transformer_layers.layers.1.attentions.0.out_proj.weight    |      (768, 768)        |             |
|      transformer_layers.layers.1.attentions.0.out_proj.bias      |      (768,)            |             |
|     transformer_layers.layers.1.attentions.0.in_proj             |     1.772M             |     2.789G  |
|      transformer_layers.layers.1.attentions.0.in_proj.weight     |      (2304, 768)       |             |
|      transformer_layers.layers.1.attentions.0.in_proj.bias       |      (2304,)           |             |
|     transformer_layers.layers.1.attentions.0.block_out           |     0.591M             |     0.93G   |
|      transformer_layers.layers.1.attentions.0.block_out.weight   |      (768, 768)        |             |
|      transformer_layers.layers.1.attentions.0.block_out.bias     |      (768,)            |             |
|     transformer_layers.layers.1.attentions.0.temporal_fc         |     0.591M             |     0.925G  |
|      transformer_layers.layers.1.attentions.0.temporal_fc.weight |      (768, 768)        |             |
|      transformer_layers.layers.1.attentions.0.temporal_fc.bias   |      (768,)            |             |
|    transformer_layers.layers.1.ffns.0                            |    4.724M              |    7.409G   |
|     transformer_layers.layers.1.ffns.0.layers                    |     4.722M             |     7.403G  |
|      transformer_layers.layers.1.ffns.0.layers.0.0               |      2.362M            |      3.702G |
|       transformer_layers.layers.1.ffns.0.layers.0.0.weight       |       (3072, 768)      |             |
|       transformer_layers.layers.1.ffns.0.layers.0.0.bias         |       (3072,)          |             |
|      transformer_layers.layers.1.ffns.0.layers.1                 |      2.36M             |      3.702G |
|       transformer_layers.layers.1.ffns.0.layers.1.weight         |       (768, 3072)      |             |
|       transformer_layers.layers.1.ffns.0.layers.1.bias           |       (768,)           |             |
|     transformer_layers.layers.1.ffns.0.norm                      |     1.536K             |     6.025M  |
|      transformer_layers.layers.1.ffns.0.norm.weight              |      (768,)            |             |
|      transformer_layers.layers.1.ffns.0.norm.bias                |      (768,)            |             |
|   transformer_layers.layers.2                                    |   10.042M              |   16.729G   |
|    transformer_layers.layers.2.attentions.0                      |    5.318M              |    9.32G    |
|     transformer_layers.layers.2.attentions.0.norm1               |     1.536K             |     6.774M  |
|      transformer_layers.layers.2.attentions.0.norm1.weight       |      (768,)            |             |
|      transformer_layers.layers.2.attentions.0.norm1.bias         |      (768,)            |             |
|     transformer_layers.layers.2.attentions.0.norm2               |     1.536K             |     6.052M  |
|      transformer_layers.layers.2.attentions.0.norm2.weight       |      (768,)            |             |
|      transformer_layers.layers.2.attentions.0.norm2.bias         |      (768,)            |             |
|     transformer_layers.layers.2.attentions.0.block_in            |     1.772M             |     3.121G  |
|      transformer_layers.layers.2.attentions.0.block_in.weight    |      (2304, 768)       |             |
|      transformer_layers.layers.2.attentions.0.block_in.bias      |      (2304,)           |             |
|     transformer_layers.layers.2.attentions.0.out_proj            |     0.591M             |     1.04G   |
|      transformer_layers.layers.2.attentions.0.out_proj.weight    |      (768, 768)        |             |
|      transformer_layers.layers.2.attentions.0.out_proj.bias      |      (768,)            |             |
|     transformer_layers.layers.2.attentions.0.in_proj             |     1.772M             |     2.789G  |
|      transformer_layers.layers.2.attentions.0.in_proj.weight     |      (2304, 768)       |             |
|      transformer_layers.layers.2.attentions.0.in_proj.bias       |      (2304,)           |             |
|     transformer_layers.layers.2.attentions.0.block_out           |     0.591M             |     0.93G   |
|      transformer_layers.layers.2.attentions.0.block_out.weight   |      (768, 768)        |             |
|      transformer_layers.layers.2.attentions.0.block_out.bias     |      (768,)            |             |
|     transformer_layers.layers.2.attentions.0.temporal_fc         |     0.591M             |     0.925G  |
|      transformer_layers.layers.2.attentions.0.temporal_fc.weight |      (768, 768)        |             |
|      transformer_layers.layers.2.attentions.0.temporal_fc.bias   |      (768,)            |             |
|    transformer_layers.layers.2.ffns.0                            |    4.724M              |    7.409G   |
|     transformer_layers.layers.2.ffns.0.layers                    |     4.722M             |     7.403G  |
|      transformer_layers.layers.2.ffns.0.layers.0.0               |      2.362M            |      3.702G |
|       transformer_layers.layers.2.ffns.0.layers.0.0.weight       |       (3072, 768)      |             |
|       transformer_layers.layers.2.ffns.0.layers.0.0.bias         |       (3072,)          |             |
|      transformer_layers.layers.2.ffns.0.layers.1                 |      2.36M             |      3.702G |
|       transformer_layers.layers.2.ffns.0.layers.1.weight         |       (768, 3072)      |             |
|       transformer_layers.layers.2.ffns.0.layers.1.bias           |       (768,)           |             |
|     transformer_layers.layers.2.ffns.0.norm                      |     1.536K             |     6.025M  |
|      transformer_layers.layers.2.ffns.0.norm.weight              |      (768,)            |             |
|      transformer_layers.layers.2.ffns.0.norm.bias                |      (768,)            |             |
|   transformer_layers.layers.3                                    |   10.042M              |   16.729G   |
|    transformer_layers.layers.3.attentions.0                      |    5.318M              |    9.32G    |
|     transformer_layers.layers.3.attentions.0.norm1               |     1.536K             |     6.774M  |
|      transformer_layers.layers.3.attentions.0.norm1.weight       |      (768,)            |             |
|      transformer_layers.layers.3.attentions.0.norm1.bias         |      (768,)            |             |
|     transformer_layers.layers.3.attentions.0.norm2               |     1.536K             |     6.052M  |
|      transformer_layers.layers.3.attentions.0.norm2.weight       |      (768,)            |             |
|      transformer_layers.layers.3.attentions.0.norm2.bias         |      (768,)            |             |
|     transformer_layers.layers.3.attentions.0.block_in            |     1.772M             |     3.121G  |
|      transformer_layers.layers.3.attentions.0.block_in.weight    |      (2304, 768)       |             |
|      transformer_layers.layers.3.attentions.0.block_in.bias      |      (2304,)           |             |
|     transformer_layers.layers.3.attentions.0.out_proj            |     0.591M             |     1.04G   |
|      transformer_layers.layers.3.attentions.0.out_proj.weight    |      (768, 768)        |             |
|      transformer_layers.layers.3.attentions.0.out_proj.bias      |      (768,)            |             |
|     transformer_layers.layers.3.attentions.0.in_proj             |     1.772M             |     2.789G  |
|      transformer_layers.layers.3.attentions.0.in_proj.weight     |      (2304, 768)       |             |
|      transformer_layers.layers.3.attentions.0.in_proj.bias       |      (2304,)           |             |
|     transformer_layers.layers.3.attentions.0.block_out           |     0.591M             |     0.93G   |
|      transformer_layers.layers.3.attentions.0.block_out.weight   |      (768, 768)        |             |
|      transformer_layers.layers.3.attentions.0.block_out.bias     |      (768,)            |             |
|     transformer_layers.layers.3.attentions.0.temporal_fc         |     0.591M             |     0.925G  |
|      transformer_layers.layers.3.attentions.0.temporal_fc.weight |      (768, 768)        |             |
|      transformer_layers.layers.3.attentions.0.temporal_fc.bias   |      (768,)            |             |
|    transformer_layers.layers.3.ffns.0                            |    4.724M              |    7.409G   |
|     transformer_layers.layers.3.ffns.0.layers                    |     4.722M             |     7.403G  |
|      transformer_layers.layers.3.ffns.0.layers.0.0               |      2.362M            |      3.702G |
|       transformer_layers.layers.3.ffns.0.layers.0.0.weight       |       (3072, 768)      |             |
|       transformer_layers.layers.3.ffns.0.layers.0.0.bias         |       (3072,)          |             |
|      transformer_layers.layers.3.ffns.0.layers.1                 |      2.36M             |      3.702G |
|       transformer_layers.layers.3.ffns.0.layers.1.weight         |       (768, 3072)      |             |
|       transformer_layers.layers.3.ffns.0.layers.1.bias           |       (768,)           |             |
|     transformer_layers.layers.3.ffns.0.norm                      |     1.536K             |     6.025M  |
|      transformer_layers.layers.3.ffns.0.norm.weight              |      (768,)            |             |
|      transformer_layers.layers.3.ffns.0.norm.bias                |      (768,)            |             |
|   transformer_layers.layers.4                                    |   10.042M              |   16.729G   |
|    transformer_layers.layers.4.attentions.0                      |    5.318M              |    9.32G    |
|     transformer_layers.layers.4.attentions.0.norm1               |     1.536K             |     6.774M  |
|      transformer_layers.layers.4.attentions.0.norm1.weight       |      (768,)            |             |
|      transformer_layers.layers.4.attentions.0.norm1.bias         |      (768,)            |             |
|     transformer_layers.layers.4.attentions.0.norm2               |     1.536K             |     6.052M  |
|      transformer_layers.layers.4.attentions.0.norm2.weight       |      (768,)            |             |
|      transformer_layers.layers.4.attentions.0.norm2.bias         |      (768,)            |             |
|     transformer_layers.layers.4.attentions.0.block_in            |     1.772M             |     3.121G  |
|      transformer_layers.layers.4.attentions.0.block_in.weight    |      (2304, 768)       |             |
|      transformer_layers.layers.4.attentions.0.block_in.bias      |      (2304,)           |             |
|     transformer_layers.layers.4.attentions.0.out_proj            |     0.591M             |     1.04G   |
|      transformer_layers.layers.4.attentions.0.out_proj.weight    |      (768, 768)        |             |
|      transformer_layers.layers.4.attentions.0.out_proj.bias      |      (768,)            |             |
|     transformer_layers.layers.4.attentions.0.in_proj             |     1.772M             |     2.789G  |
|      transformer_layers.layers.4.attentions.0.in_proj.weight     |      (2304, 768)       |             |
|      transformer_layers.layers.4.attentions.0.in_proj.bias       |      (2304,)           |             |
|     transformer_layers.layers.4.attentions.0.block_out           |     0.591M             |     0.93G   |
|      transformer_layers.layers.4.attentions.0.block_out.weight   |      (768, 768)        |             |
|      transformer_layers.layers.4.attentions.0.block_out.bias     |      (768,)            |             |
|     transformer_layers.layers.4.attentions.0.temporal_fc         |     0.591M             |     0.925G  |
|      transformer_layers.layers.4.attentions.0.temporal_fc.weight |      (768, 768)        |             |
|      transformer_layers.layers.4.attentions.0.temporal_fc.bias   |      (768,)            |             |
|    transformer_layers.layers.4.ffns.0                            |    4.724M              |    7.409G   |
|     transformer_layers.layers.4.ffns.0.layers                    |     4.722M             |     7.403G  |
|      transformer_layers.layers.4.ffns.0.layers.0.0               |      2.362M            |      3.702G |
|       transformer_layers.layers.4.ffns.0.layers.0.0.weight       |       (3072, 768)      |             |
|       transformer_layers.layers.4.ffns.0.layers.0.0.bias         |       (3072,)          |             |
|      transformer_layers.layers.4.ffns.0.layers.1                 |      2.36M             |      3.702G |
|       transformer_layers.layers.4.ffns.0.layers.1.weight         |       (768, 3072)      |             |
|       transformer_layers.layers.4.ffns.0.layers.1.bias           |       (768,)           |             |
|     transformer_layers.layers.4.ffns.0.norm                      |     1.536K             |     6.025M  |
|      transformer_layers.layers.4.ffns.0.norm.weight              |      (768,)            |             |
|      transformer_layers.layers.4.ffns.0.norm.bias                |      (768,)            |             |
|   transformer_layers.layers.5                                    |   10.042M              |   16.729G   |
|    transformer_layers.layers.5.attentions.0                      |    5.318M              |    9.32G    |
|     transformer_layers.layers.5.attentions.0.norm1               |     1.536K             |     6.774M  |
|      transformer_layers.layers.5.attentions.0.norm1.weight       |      (768,)            |             |
|      transformer_layers.layers.5.attentions.0.norm1.bias         |      (768,)            |             |
|     transformer_layers.layers.5.attentions.0.norm2               |     1.536K             |     6.052M  |
|      transformer_layers.layers.5.attentions.0.norm2.weight       |      (768,)            |             |
|      transformer_layers.layers.5.attentions.0.norm2.bias         |      (768,)            |             |
|     transformer_layers.layers.5.attentions.0.block_in            |     1.772M             |     3.121G  |
|      transformer_layers.layers.5.attentions.0.block_in.weight    |      (2304, 768)       |             |
|      transformer_layers.layers.5.attentions.0.block_in.bias      |      (2304,)           |             |
|     transformer_layers.layers.5.attentions.0.out_proj            |     0.591M             |     1.04G   |
|      transformer_layers.layers.5.attentions.0.out_proj.weight    |      (768, 768)        |             |
|      transformer_layers.layers.5.attentions.0.out_proj.bias      |      (768,)            |             |
|     transformer_layers.layers.5.attentions.0.in_proj             |     1.772M             |     2.789G  |
|      transformer_layers.layers.5.attentions.0.in_proj.weight     |      (2304, 768)       |             |
|      transformer_layers.layers.5.attentions.0.in_proj.bias       |      (2304,)           |             |
|     transformer_layers.layers.5.attentions.0.block_out           |     0.591M             |     0.93G   |
|      transformer_layers.layers.5.attentions.0.block_out.weight   |      (768, 768)        |             |
|      transformer_layers.layers.5.attentions.0.block_out.bias     |      (768,)            |             |
|     transformer_layers.layers.5.attentions.0.temporal_fc         |     0.591M             |     0.925G  |
|      transformer_layers.layers.5.attentions.0.temporal_fc.weight |      (768, 768)        |             |
|      transformer_layers.layers.5.attentions.0.temporal_fc.bias   |      (768,)            |             |
|    transformer_layers.layers.5.ffns.0                            |    4.724M              |    7.409G   |
|     transformer_layers.layers.5.ffns.0.layers                    |     4.722M             |     7.403G  |
|      transformer_layers.layers.5.ffns.0.layers.0.0               |      2.362M            |      3.702G |
|       transformer_layers.layers.5.ffns.0.layers.0.0.weight       |       (3072, 768)      |             |
|       transformer_layers.layers.5.ffns.0.layers.0.0.bias         |       (3072,)          |             |
|      transformer_layers.layers.5.ffns.0.layers.1                 |      2.36M             |      3.702G |
|       transformer_layers.layers.5.ffns.0.layers.1.weight         |       (768, 3072)      |             |
|       transformer_layers.layers.5.ffns.0.layers.1.bias           |       (768,)           |             |
|     transformer_layers.layers.5.ffns.0.norm                      |     1.536K             |     6.025M  |
|      transformer_layers.layers.5.ffns.0.norm.weight              |      (768,)            |             |
|      transformer_layers.layers.5.ffns.0.norm.bias                |      (768,)            |             |
GFLOPS:	101.31 G
Params:	61.00 M

Process finished with exit code 0
